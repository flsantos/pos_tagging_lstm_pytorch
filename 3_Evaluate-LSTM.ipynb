{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instruções\n",
    "\n",
    "* Rodar o notebook em ordem\n",
    "* Arquivos necessários:\n",
    "    * preprocessed_CETEN_v2.pkl: gerado pelo notebook 1_Data_Prep.ipynb\n",
    "    * model_lstm_dicts.pkl: gerado pelo notebook 2_Train-LSTM.ipynb\n",
    "    * model_96acc_bs1_state_dict.model: gerado pelo notebook 2_Train-LSTM.ipynb\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "import logging\n",
    "import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Leitura da base pre processada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('preprocessed_CETEN_v2.pkl', 'rb') as input:\n",
    "    phrases = pickle.load(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definição de funções auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect0(lst):\n",
    "    return list(map(lambda x: x[0], lst))\n",
    "def collect1(lst):\n",
    "    return list(map(lambda x: x[1], lst))\n",
    "def batch_idx_loader(data, shuffle=True):\n",
    "    permutation = torch.randperm(len(data)) if shuffle else torch.tensor(range(len(data)))\n",
    "    gen = (permutation[b:b+BATCH_SIZE] for b in range(0,len(data), BATCH_SIZE))\n",
    "    return gen\n",
    "def get_data_sorted(data, idx):\n",
    "    data = np.array(data)\n",
    "    idx = [idx] if len(idx) == 1 else idx\n",
    "    \n",
    "    sentences = [bat[0] for bat in data[idx]]\n",
    "    tags =      [bat[1] for bat in data[idx]]\n",
    "\n",
    "    mydict     = {idx:len(s) for idx,s in enumerate(sentences)}\n",
    "    idx_sorted = [k for k in sorted(mydict, key=mydict.get, reverse=True)]\n",
    "\n",
    "    sentences = np.array(sentences)[idx_sorted]\n",
    "    tags      = np.array(tags)[idx_sorted]\n",
    "    \n",
    "    return sentences, tags\n",
    "def prepare_batch_sequence(sentences, to_ix):\n",
    "    s_lengths = [len(s) for s in sentences]\n",
    "\n",
    "    # create an empty matrix with padding tokens\n",
    "    pad_token = to_ix['<PAD>']\n",
    "    longest_sent = max(s_lengths)\n",
    "    batch_size = len(sentences)\n",
    "    padded_sentences = np.ones((batch_size, longest_sent)) * pad_token\n",
    "    # copy over the actual sequences\n",
    "    for n, s_len in enumerate(s_lengths):\n",
    "        sequence = sentences[n]\n",
    "        idxs = [to_ix[w] for w in sequence[:s_len]]\n",
    "        padded_sentences[n, 0:s_len] = idxs\n",
    "    \n",
    "    return torch.tensor(padded_sentences, dtype=torch.long)#, device=torch.device(\"cuda\"))\n",
    "\n",
    "def get_index_of_max(input):\n",
    "    index = 0\n",
    "    for i in range(1, len(input)):\n",
    "        if input[i] > input[index]:\n",
    "            index = i \n",
    "    return index\n",
    "\n",
    "def get_max_prob_result(input, ix_to_tag):\n",
    "    return ix_to_tag[get_index_of_max(input)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOAD LSTM MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "###Important for reproductability\n",
    "torch.manual_seed(1)\n",
    "np.random.seed(1)\n",
    "random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=2753"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "##BACKUP WORKING LSTM biredirectional with gloves100\n",
    "class LSTMTagger(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size, word_to_ix, embedding_weights=None):\n",
    "        super(LSTMTagger, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.tagset_size = tagset_size\n",
    "\n",
    "        padding_idx = word_to_ix['<PAD>']\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=padding_idx)#.cuda()\n",
    "        if embedding_weights:\n",
    "            self.word_embeddings.weight.data.copy_(torch.from_numpy(embedding_weights))\n",
    "        \n",
    "        self.num_layers = 1\n",
    "\n",
    "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
    "        # with dimensionality hidden_dim.\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, self.num_layers, batch_first=False, bidirectional=True)#.cuda()\n",
    "\n",
    "        # The linear layer that maps from hidden state space to tag space\n",
    "        self.hidden2tag = nn.Linear(hidden_dim*2, tagset_size)#.cuda()\n",
    "        self.hidden = self.init_hidden()\n",
    "\n",
    "    def init_hidden(self):\n",
    "        # Before we've done anything, we dont have any hidden state.\n",
    "        # Refer to the Pytorch documentation to see exactly\n",
    "        # why they have this dimensionality.\n",
    "        # The axes semantics are (num_layers, minibatch_size, hidden_dim)\n",
    "        return (torch.zeros(self.num_layers*2, BATCH_SIZE, self.hidden_dim),#.cuda(),\n",
    "                torch.zeros(self.num_layers*2, BATCH_SIZE, self.hidden_dim))#.cuda())\n",
    "        #return torch.zeros(1, 1, self.hidden_dim)\n",
    "\n",
    "    def forward(self, sentence, s_lengths, debug=False):\n",
    "        batch_size, seq_len, = sentence.size()\n",
    "        \n",
    "        \n",
    "        \n",
    "        if debug: print(\"sentences input:\", sentence.size())\n",
    "        # 1. embed the input\n",
    "        # Dim transformation: (batch_size, seq_len, 1) -> (batch_size, seq_len, embedding_dim)\n",
    "        embeds = self.word_embeddings(sentence)\n",
    "        if debug: print(\"embeds:\",embeds.size())\n",
    "        \n",
    "        # 2. Run through RNN\n",
    "        # TRICK 2 ********************************\n",
    "        # Dim transformation: (batch_size, seq_len, embedding_dim) -> (batch_size, seq_len, nb_lstm_units)\n",
    "        \n",
    "        embeds = embeds.transpose(0,1)\n",
    "        # pack_padded_sequence so that padded items in the sequence won't be shown to the LSTM\n",
    "        lstm_input = torch.nn.utils.rnn.pack_padded_sequence(embeds, s_lengths, batch_first=False)        \n",
    "        #lstm_input = embeds.view(seq_len, BATCH_SIZE, -1)\n",
    "        #lstm_input = embeds.transpose(0,1)\n",
    "        if debug: print(\"lstm_input:\",lstm_input.data.size())\n",
    "        \n",
    "        if debug: print(\"hidden0 (ht):\",self.hidden[0].size())\n",
    "        if debug: print(\"hidden1 (hc):\",self.hidden[1].size())    \n",
    "        # now run through LSTM\n",
    "        lstm_out, self.hidden = self.lstm(lstm_input, self.hidden)\n",
    "        \n",
    "        if debug: print(\"lstm_out:\", lstm_out.data.size())\n",
    "        if debug: print(\"hidden0 (ht):\",self.hidden[0].size())\n",
    "        if debug: print(\"hidden1 (hc):\",self.hidden[1].size())    \n",
    "        \n",
    "        # undo the packing operation\n",
    "        lstm_out, _ = torch.nn.utils.rnn.pad_packed_sequence(lstm_out, batch_first=False)\n",
    "        #print(\"lstm_out:\", lstm_out.data.size())\n",
    "        \n",
    "        \n",
    "        # 3. Project to tag space\n",
    "        # Dim transformation: (batch_size, seq_len, nb_lstm_units) -> (batch_size * seq_len, nb_lstm_units)\n",
    "\n",
    "        # this one is a bit tricky as well. First we need to reshape the data so it goes into the linear layer\n",
    "        #lstm_out = lstm_out.contiguous()\n",
    "        #lstm_out = lstm_out.view(-1, lstm_out.shape[2])\n",
    "        #lstm_out = lstm_out.view(seq_len, -1)\n",
    "        \n",
    "        ##OPTION1 \n",
    "        #batch_first = lstm_out.transpose(0,1)\n",
    "        #print(\"batch_first:\", batch_first.size())\n",
    "        #batch_first = batch_first.contiguous()\n",
    "        #print(\"batch_first(contiguous):\", batch_first.size())\n",
    "        #linear_input = batch_first.view(BATCH_SIZE, -1)\n",
    "        ### Para fazer isso, preciso setar o input da Linear ao inves de 200, para 200*N,\n",
    "        #onde N é o tamanho da maior sentença da base toda\n",
    "        \n",
    "        \n",
    "        \n",
    "        ###OPTION2\n",
    "        #linear_input = self.hidden[0]\n",
    "        \n",
    "        \n",
    "        ##option3\n",
    "        lstm_out = lstm_out.transpose(0,1)\n",
    "        lstm_out = lstm_out.contiguous()\n",
    "        if debug: print(\"lstm_out reshaped:\", lstm_out.size())\n",
    "        linear_input = lstm_out.view(-1, lstm_out.shape[2])\n",
    "        if debug: print(\"linear_input:\", linear_input.size())\n",
    "        \n",
    "        \n",
    "        \n",
    "        tag_space = self.hidden2tag(linear_input)\n",
    "        if debug: print(\"hidden out :\", tag_space.size())\n",
    "        tag_scores = F.log_softmax(tag_space, dim=1)\n",
    "        \n",
    "        #tag_scores = tag_scores.view(BATCH_SIZE, seq_len, self.tagset_size)\n",
    "        return tag_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LOAD MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "RARE_WORD = '__RARE__'\n",
    "with open('model_lstm_dicts.pkl', 'rb') as f:\n",
    "    model_dicts = pickle.load(f)\n",
    "    word_to_ix = model_dicts['word_to_ix']\n",
    "    tag_to_ix = model_dicts['tag_to_ix']\n",
    "    ix_to_tag = model_dicts['ix_to_tag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMTagger(\n",
       "  (word_embeddings): Embedding(59709, 100, padding_idx=0)\n",
       "  (lstm): LSTM(100, 200, bidirectional=True)\n",
       "  (hidden2tag): Linear(in_features=400, out_features=17, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EMBEDDING_DIM=100 #Alterar para 50 caso a rede tenha sido treinada com GLOVE50 ao invés de glove100\n",
    "HIDDEN_DIM=200\n",
    "lstm_model = LSTMTagger(EMBEDDING_DIM, HIDDEN_DIM, len(word_to_ix), len(tag_to_ix), word_to_ix)\n",
    "lstm_model.load_state_dict(torch.load('./model_96acc_bs1_state_dict.model', map_location='cpu'))\n",
    "lstm_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PREPARE TEST DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_lstm(phrases_to_test):\n",
    "    with torch.no_grad():\n",
    "        phrases_test_with_rare = []\n",
    "\n",
    "        ### Ajusta tamanho do teste para ser multiplo do batchsize\n",
    "        testwith=len(phrases_to_test)\n",
    "        testwith = int(testwith/BATCH_SIZE)*BATCH_SIZE\n",
    "\n",
    "        ### Add RARE \n",
    "        for s in phrases_to_test[:testwith]:\n",
    "            phrases_test_with_rare.append([(tk[0],tk[1]) if word_to_ix.get(tk[0]) != None else (RARE_WORD,tk[1]) for tk in s])\n",
    "\n",
    "        ###Define test dataset    \n",
    "        validating_data_phrases = [(collect0(p),collect1(p)) for p in phrases_test_with_rare]\n",
    "\n",
    "        since = time.time()\n",
    "\n",
    "        preds=[]\n",
    "        dt = validating_data_phrases\n",
    "        loader = batch_idx_loader(dt, shuffle=False)\n",
    "        count=0\n",
    "        for indices in loader:\n",
    "            sentences, tags = get_data_sorted(dt, indices)\n",
    "\n",
    "            count+=len(sentences)\n",
    "            if count % 27530 == 0:\n",
    "                print(count)\n",
    "\n",
    "            sentence_in = prepare_batch_sequence(sentences,word_to_ix)\n",
    "            targets = prepare_batch_sequence(tags, tag_to_ix)\n",
    "\n",
    "            s_lengths = [len(s) for s in sentences]\n",
    "            tag_scores = lstm_model(sentence_in, s_lengths)\n",
    "            tag_scores = tag_scores.view(BATCH_SIZE, s_lengths[0], len(tag_to_ix))\n",
    "\n",
    "            for batchline in range(tag_scores.shape[0]):\n",
    "                pred = [get_max_prob_result(tag_scores[batchline][wordidx].data.cpu().numpy(), ix_to_tag) for wordidx in range(s_lengths[batchline])]\n",
    "                preds.append([(word, golden, tk) for word, golden, tk in zip(sentences[batchline], tags[batchline], pred)])\n",
    "\n",
    "        corretas_rnn = 0\n",
    "        totais = 0\n",
    "        for pred in preds:\n",
    "            for word, tk_golden, tk_pred in pred:\n",
    "                #print(tk_golden)\n",
    "                totais+=1\n",
    "                if tk_golden == tk_pred:\n",
    "                    corretas_rnn+=1\n",
    "\n",
    "        time_elapsed = time.time() - since\n",
    "        #print('Eval complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "\n",
    "        return corretas_rnn, totais, corretas_rnn/totais*100, time_elapsed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43150, 44585, 96.7814287316362, 3.1840274333953857)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_lstm(phrases[:5000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avaliação na base completa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(filename='evaluation.log', level=logging.INFO)\n",
    "def log(msg):\n",
    "    logging.info(datetime.datetime.now().strftime(\"%d.%b %Y %H:%M:%S\")+ ': '+str(msg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Round 1\n",
      "Train test split: 1354480,338621\n",
      "LSTM running...\n",
      "27530\n",
      "55060\n",
      "82590\n",
      "110120\n",
      "137650\n",
      "165180\n",
      "192710\n",
      "220240\n",
      "247770\n",
      "275300\n",
      "302830\n",
      "330360\n",
      "2.8733291625976562\n",
      "2.8733291625976562\n",
      "2.8733291625976562\n",
      "5317961 5502766 96.64159806177474 233.8405246734619\n",
      "\n",
      "CV Round 2\n",
      "Train test split: 1354481,338620\n",
      "LSTM running...\n",
      "27530\n",
      "55060\n",
      "82590\n",
      "110120\n",
      "137650\n",
      "165180\n",
      "192710\n",
      "220240\n",
      "247770\n",
      "275300\n",
      "302830\n",
      "330360\n",
      "2.8733291625976562\n",
      "2.8733291625976562\n",
      "2.8733291625976562\n",
      "5325037 5498998 96.83649639443404 239.1606993675232\n",
      "\n",
      "CV Round 3\n",
      "Train test split: 1354481,338620\n",
      "LSTM running...\n",
      "27530\n",
      "55060\n",
      "82590\n",
      "110120\n",
      "137650\n",
      "165180\n",
      "192710\n",
      "220240\n",
      "247770\n",
      "275300\n",
      "302830\n",
      "330360\n",
      "2.8733291625976562\n",
      "2.8733291625976562\n",
      "2.8733291625976562\n",
      "5338313 5523072 96.65477835523419 234.00328469276428\n",
      "\n",
      "CV Round 4\n",
      "Train test split: 1354481,338620\n",
      "LSTM running...\n",
      "27530\n",
      "55060\n",
      "82590\n",
      "110120\n",
      "137650\n",
      "165180\n",
      "192710\n",
      "220240\n",
      "247770\n",
      "275300\n",
      "302830\n",
      "330360\n",
      "2.8733291625976562\n",
      "2.8733291625976562\n",
      "2.8733291625976562\n",
      "5333106 5517859 96.65172669326998 234.37831377983093\n",
      "\n",
      "CV Round 5\n",
      "Train test split: 1354481,338620\n",
      "LSTM running...\n",
      "27530\n",
      "55060\n",
      "82590\n",
      "110120\n",
      "137650\n",
      "165180\n",
      "192710\n",
      "220240\n",
      "247770\n",
      "275300\n",
      "302830\n",
      "330360\n",
      "2.8733291625976562\n",
      "2.8733291625976562\n",
      "2.8733291625976562\n",
      "5313108 5497526 96.64543651089599 233.75838661193848\n",
      "\n"
     ]
    }
   ],
   "source": [
    "phrases_data = np.array(phrases)\n",
    "round = 0\n",
    "for train_index, test_index in kf.split(phrases_data):\n",
    "    round=round+1\n",
    "    print('CV Round '+str(round))\n",
    "    log('CV Round '+str(round))\n",
    "    \n",
    "    print('Train test split: '+ str(len(train_index))+','+str(len(test_index)))\n",
    "    log('Train test split: '+ str(len(train_index))+','+str(len(test_index)))\n",
    "    phrases_train = phrases_data[train_index]\n",
    "    phrases_test = phrases_data[test_index]\n",
    "    \n",
    "    \n",
    "    print('LSTM running...')\n",
    "    log('LSTM running...')\n",
    "    corretas_lstm, totais, acc, time_elapsed = evaluate_lstm(phrases_test)\n",
    "\n",
    "    \n",
    "    print(corretas_lstm, totais, acc, time_elapsed)\n",
    "    log(str([corretas_lstm, totais, acc, time_elapsed]))\n",
    "    \n",
    "    print(\"\")\n",
    "    log(\"\")\n",
    "    \n",
    "logging.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
